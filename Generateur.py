import streamlit as st
import pandas as pd
import logging
import time
import httpx
import io
import json
from notion_client import Client
from notion_client.errors import RequestTimeoutError, APIResponseError
from datetime import datetime # Import ajout√© pour le traitement des dates

# --- Configuration du logger ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- Constantes pour l'extraction de recettes et menus ---
SAISON_FILTRE = "Printemps" # Peut √™tre rendu configurable via un widget Streamlit si d√©sir√©
NUM_ROWS_TO_EXTRACT = 100000 # Augment√© pour l'extraction des menus
BATCH_SIZE = 50
MAX_RETRIES = 7
RETRY_DELAY_INITIAL = 10
API_TIMEOUT_SECONDS = 180

# --- Connexion √† Notion et IDs des bases de donn√©es ---
try:
    NOTION_API_KEY = st.secrets["notion_api_key"]
    DATABASE_ID_INGREDIENTS = st.secrets["notion_database_id_ingredients"]
    DATABASE_ID_INGREDIENTS_RECETTES = st.secrets["notion_database_id_ingredients_recettes"]
    DATABASE_ID_RECETTES = st.secrets["notion_database_id_recettes"]
    DATABASE_ID_MENUS = st.secrets["notion_database_id_menus"] # ID pour la base de donn√©es des Menus

    notion = Client(auth=NOTION_API_KEY)
except KeyError as e:
    st.error(f"Le secret Notion manquant est : {e}. "
             "Veuillez configurer tous les secrets Notion dans le fichier .streamlit/secrets.toml "
             "ou via l'interface Streamlit Cloud. "
             "Assurez-vous d'avoir: notion_api_key, notion_database_id_ingredients, "
             "notion_database_id_ingredients_recettes, notion_database_id_recettes, "
             "notion_database_id_menus.")
    st.stop()

# ========== FONCTION D'EXTRACTION DE PROPRI√âT√âS SP√âCIFIQUE POUR LES RECETTES ==========
# Cette fonction est bas√©e sur le 'get_property_value' fourni par l'utilisateur
def extract_recette_property_value(prop_data, notion_prop_name_for_log, expected_format_key):
    if not prop_data: return ""
    prop_type = prop_data.get("type")

    try:
        if expected_format_key == "title":
            return "".join(t.get("text", {}).get("content", "") for t in prop_data.get("title", []))
        elif expected_format_key == "rollup_text_concat":
            if prop_type == "rollup":
                arr = prop_data.get("rollup", {}).get("array", [])
                values = []
                for item in arr:
                    if item.get("type") == "rich_text": values.append("".join(t.get("plain_text", "") for t in item.get("rich_text", [])))
                    elif item.get("type") == "title": values.append("".join(t.get("text", {}).get("content", "") for t in item.get("title", [])))
                return ", ".join(filter(None, values))
            return ""
        elif expected_format_key == "unique_id_or_text":
            if prop_type == "unique_id":
                uid = prop_data.get("unique_id", {}); p, n = uid.get("prefix"), uid.get("number")
                return f"{p}-{n}" if p and n is not None else (str(n) if n is not None else "")
            elif prop_type == "title": return extract_recette_property_value(prop_data, notion_prop_name_for_log, "title")
            elif prop_type == "rich_text": return extract_recette_property_value(prop_data, notion_prop_name_for_log, "rich_text_plain")
            return ""
        elif expected_format_key == "rich_text_plain":
             return "".join(t.get("plain_text", "") for t in prop_data.get("rich_text", []))
        elif expected_format_key == "multi_select_comma_separated":
            if prop_type == "multi_select":
                return ", ".join(filter(None, [o.get("name", "") for o in prop_data.get("multi_select", [])]))
            return ""
        elif expected_format_key == "number_to_string_or_empty":
            if prop_type == "number": num = prop_data.get("number"); return str(num) if num is not None else ""
            return ""
        elif expected_format_key == "formula_number_or_string_or_empty":
            if prop_type == "formula":
                fo = prop_data.get("formula", {}); ft = fo.get("type")
                if ft == "number": num = fo.get("number"); return str(num) if num is not None else ""
                elif ft == "string": return fo.get("string", "")
            return ""
        elif expected_format_key == "rollup_single_number_or_empty":
             if prop_type == "rollup":
                ro = prop_data.get("rollup", {}); rt = ro.get("type")
                if rt == "number": num = ro.get("number"); return str(num) if num is not None else ""
                elif rt == "array":
                    arr = ro.get("array", [])
                    if arr:
                        item = arr[0]; it = item.get("type")
                        if it == "number": num = item.get("number"); return str(num) if num is not None else ""
                        elif it == "formula":
                            fi = item.get("formula", {}); fit = fi.get("type")
                            if fit == "number": num = fi.get("number"); return str(num) if num is not None else ""
             return ""
        elif expected_format_key == "rollup_formula_string_dots_comma_separated":
            if prop_type == "rollup":
                arr = prop_data.get("rollup", {}).get("array", [])
                vals = []
                for item in arr:
                    if item.get("type") == "formula":
                        fo = item.get("formula", {}); ft = fo.get("type")
                        if ft == "string": sv = fo.get("string"); vals.append(sv if sv and sv.strip() else ".")
                        else: vals.append(".")
                    else: vals.append(".")
                return ", ".join(vals)
            return ""
        elif expected_format_key == "select_to_oui_empty":
            if prop_type == "select":
                so = prop_data.get("select"); return "Oui" if so and so.get("name", "").lower() == "oui" else ""
            elif prop_type == "checkbox": return "Oui" if prop_data.get("checkbox", False) else ""
            return ""
    except Exception as e:
        logger.error(f"EXC Formatage: '{notion_prop_name_for_log}' (format: {expected_format_key}): {e}", exc_info=False)
        return "ERREUR_FORMAT"
    return ""

# --- Fonctions d'extraction de propri√©t√©s Notion (PREEXISTANTES ET PLUS G√âN√âRIQUES) ---
# Ceci est l'ancienne fonction extract_property_value qui est utilis√©e par fetch_notion_data
# pour les bases de donn√©es Ingr√©dients et Ingr√©dients_recettes.
def extract_property_value_generic(prop):
    if not isinstance(prop, dict):
        return ""
    t = prop.get("type")
    if t == "title":
        return "".join([t.get("plain_text", "") for t in prop.get("title", [])])
    elif t == "rich_text":
        return "".join([t.get("plain_text", "") for t in prop.get("rich_text", [])])
    elif t == "multi_select":
        return ", ".join([opt.get("name", "") for opt in prop.get("multi_select", [])])
    elif t == "select":
        select_obj = prop.get("select")
        if select_obj is not None:
            return select_obj.get("name", "")
        return ""
    elif t == "number":
        return str(prop.get("number", ""))
    elif t == "checkbox":
        return str(prop.get("checkbox", ""))
    elif t == "date":
        date_obj = prop.get("date")
        if date_obj is not None:
            return date_obj.get("start", "")
        return ""
    elif t == "people":
        return ", ".join([person.get("name", "") for person in prop.get("people", [])])
    elif t == "relation":
        return ", ".join([rel.get("id", "") for rel in prop.get("relation", [])])
    elif t == "url":
        return prop.get("url", "")
    elif t == "email":
        return prop.get("email", "")
    elif t == "phone_number":
        return prop.get("phone_number", "")
    elif t == "formula":
        formula = prop.get("formula", {})
        if formula.get("type") == "string":
            return formula.get("string", "")
        elif formula.get("type") == "number":
            return str(formula.get("number", ""))
        elif formula.get("type") == "boolean":
            return str(formula.get("boolean", ""))
        elif formula.get("type") == "date":
            date_obj = formula.get("date")
            if date_obj is not None:
                return date_obj.get("start", "")
            return ""
    elif t == "rollup":
        rollup = prop.get("rollup", {})
        if rollup.get("type") == "array":
            extracted_items = []
            for item in rollup.get("array", []):
                if item.get("type") == "text":
                    extracted_items.append(item.get("text", {}).get("plain_text", ""))
                elif item.get("type") == "number":
                    extracted_items.append(str(item.get("number", "")))
            return ", ".join(extracted_items)
        elif rollup.get("type") in ["number", "string", "boolean", "date"]:
            return str(rollup.get(rollup.get("type"), ""))
    return ""

# --- Fonctions de r√©cup√©ration des donn√©es Notion avec Caching Streamlit ---
@st.cache_data(show_spinner="Chargement des donn√©es Notion...", ttl=3600) # Cache pendant 1 heure
def fetch_notion_data(database_id: str, filter_json_str: str = None, columns_mapping: dict = None):
    """
    R√©cup√®re les donn√©es d'une base de donn√©es Notion et les retourne sous forme de DataFrame.
    G√®re la pagination et les retries.
    filter_json_str: Filtre de la requ√™te Notion s√©rialis√© en JSON string (pour la compatibilit√© du cache).
    columns_mapping: Dictionnaire de mappage des noms de propri√©t√©s Notion vers les noms de colonnes DataFrame.
    """
    all_rows = []
    next_cursor = None
    total_extracted = 0

    filter_cond = json.loads(filter_json_str) if filter_json_str else {}

    logger.info(f"D√©but de l'extraction de la base de donn√©es Notion: {database_id}")

    while True:
        try:
            query_params = {
                "database_id": database_id,
                "page_size": BATCH_SIZE,
                "timeout": API_TIMEOUT_SECONDS,
            }
            if next_cursor:
                query_params["start_cursor"] = next_cursor
            if filter_cond:
                query_params["filter"] = filter_cond

            results = notion.databases.query(**query_params)
            page_results = results.get("results", [])

            if not page_results:
                logger.info(f"Fin de l'extraction ou aucun r√©sultat pour {database_id}.")
                break

            for result in page_results:
                properties = result.get("properties", {})
                row_data = {"Page_ID": result.get("id", "")}

                if columns_mapping:
                    for notion_prop, df_col in columns_mapping.items():
                        row_data[df_col] = extract_property_value_generic(properties.get(notion_prop, {}))
                else:
                    for prop_name, prop_data in properties.items():
                        row_data[prop_name] = extract_property_value_generic(prop_data)

                all_rows.append(row_data)
                total_extracted += 1

            next_cursor = results.get("next_cursor")
            if not next_cursor:
                break
            time.sleep(0.1)

        except (httpx.TimeoutException, RequestTimeoutError) as e:
            logger.warning(f"Timeout d√©tect√© lors de la requ√™te Notion ({database_id}): {e}. R√©essai...")
            time.sleep(5)
            continue
        except Exception as e:
            logger.exception(f"Erreur inattendue lors de l'extraction Notion de {database_id}: {e}")
            st.error(f"Erreur lors de la r√©cup√©ration des donn√©es de Notion pour la base {database_id}: {e}")
            return pd.DataFrame()

    if all_rows:
        df = pd.DataFrame(all_rows)
        logger.info(f"Extraction r√©ussie : {total_extracted} lignes de {database_id}.")
        return df
    else:
        logger.info(f"Aucune donn√©e extraite de {database_id}.")
        return pd.DataFrame()

# Fonction sp√©cifique pour la base de donn√©es Ingr√©dients
def get_ingredients_data():
    filter_cond = {"property": "Type de stock", "select": {"equals": "Autre type"}}
    columns_mapping = {
        "Nom": "Nom",
        "Type de stock": "Type de stock",
        "unit√©": "unit√©",
        "Qte reste": "Qte reste"
    }
    return fetch_notion_data(
        DATABASE_ID_INGREDIENTS,
        filter_json_str=json.dumps(filter_cond, sort_keys=True),
        columns_mapping=columns_mapping
    )

# Nouvelle fonction pour la base de donn√©es Ingr√©dients_recettes
def get_ingredients_recettes_data():
    filter_cond = {
        "property": "Type de stock f",
        "formula": {"string": {"equals": "Autre type"}}
    }
    columns_mapping = {
        "El√©ment parent": "Element_Parent_Relation_IDs",
        "Qt√©/pers_s": "Qt√©/pers_s",
        "Ingr√©dient ok": "Ingr√©dient ok",
        "Type de stock f": "Type de stock f"
    }

    df = fetch_notion_data(
        DATABASE_ID_INGREDIENTS_RECETTES,
        filter_json_str=json.dumps(filter_cond, sort_keys=True),
        columns_mapping=columns_mapping
    )

    if not df.empty and "Element_Parent_Relation_IDs" in df.columns:
        df['Page_ID_Formatted'] = df.apply(
            lambda row: row['Element_Parent_Relation_IDs'].split(',')[0].strip() if row['Element_Parent_Relation_IDs'] else row['Page_ID'],
            axis=1
        )
        df['Page_ID'] = df['Page_ID_Formatted']
        df = df.drop(columns=['Page_ID_Formatted', 'Element_Parent_Relation_IDs'])

        if 'Qt√©/pers_s' in df.columns:
            df['Qt√©/pers_s'] = pd.to_numeric(
                df['Qt√©/pers_s'].astype(str).str.replace(',', '.').replace('', '0'),
                errors='coerce'
            ).fillna(0)

            df = df[df['Qt√©/pers_s'] > 0]

    desired_columns = ["Page_ID", "Qt√©/pers_s", "Ingr√©dient ok", "Type de stock f"]
    existing_columns = [col for col in desired_columns if col in df.columns]
    df = df[existing_columns]

    return df

# ========== NOUVELLE FONCTION POUR R√âCUP√âRER LES DONN√âES DE LA BASE DE DONN√âES "RECETTES" ==========
@st.cache_data(show_spinner="Chargement des recettes depuis Notion...", ttl=3600)
def get_recettes_data():
    all_recettes_rows = []
    next_cursor = None
    total_extracted_from_api = 0

    filter_conditions = [
        {"property": "El√©ment parent", "relation": {"is_empty": True}},
        {
            "or": [
                {"property": "Saison", "multi_select": {"contains": "Toute l'ann√©e"}},
                *([{"property": "Saison", "multi_select": {"contains": SAISON_FILTRE}}] if SAISON_FILTRE else []),
                {"property": "Saison", "multi_select": {"is_empty": True}}
            ]
        },
        {
            "or": [
                {"property": "Type_plat", "multi_select": {"contains": "Salade"}},
                {"property": "Type_plat", "multi_select": {"contains": "Soupe"}},
                {"property": "Type_plat", "multi_select": {"contains": "Plat"}}
            ]
        }
    ]
    filter_recettes = {"and": filter_conditions}
    logger.info(f"Filtre API Notion pour Recettes : {filter_recettes}")

    # Noms de propri√©t√©s Notion v√©rifi√©s par rapport √† votre liste
    csv_to_notion_mapping = {
        "Page_ID":          (None, "page_id_special"),
        "Nom":              ("Nom_plat", "title"),
        "ID_Recette":       ("ID_Recette", "unique_id_or_text"),
        "Saison":           ("Saison", "multi_select_comma_separated"),
        "Calories":         ("Calories Recette", "rollup_single_number_or_empty"),
        "Proteines":        ("Proteines Recette", "rollup_single_number_or_empty"),
        "Temps_total":      ("Temps_total", "formula_number_or_string_or_empty"),
        "Aime_pas_princip": ("Aime_pas_princip", "rollup_formula_string_dots_comma_separated"),
        "Type_plat":        ("Type_plat", "multi_select_comma_separated"),
        "Transportable":    ("Transportable", "select_to_oui_empty")
    }

    while total_extracted_from_api < NUM_ROWS_TO_EXTRACT: # Utilise NUM_ROWS_TO_EXTRACT global
        retries = 0
        current_retry_delay = RETRY_DELAY_INITIAL

        try:
            query_params = {"database_id": DATABASE_ID_RECETTES, "filter": filter_recettes, "page_size": BATCH_SIZE}
            if next_cursor: query_params["start_cursor"] = next_cursor

            logger.info(f"Appel API Notion pour Recettes (Curseur: {next_cursor or 'aucun'}).")
            response = notion.databases.query(**query_params)

            pages_batch = response.get("results", [])
            total_extracted_from_api += len(pages_batch)
            logger.info(f"API Recettes a retourn√© {len(pages_batch)} pages pour ce lot. (Total API: {total_extracted_from_api})")

            next_cursor = response.get("next_cursor")

        except (RequestTimeoutError, httpx.TimeoutException, httpx.ReadTimeout) as e:
            retries += 1; logger.warning(f"Timeout API Recettes (tentative {retries}/{MAX_RETRIES}). Attente {current_retry_delay}s...")
            if retries >= MAX_RETRIES: logger.error(f"Max timeouts atteints pour Recettes. Abandon."); break
            time.sleep(current_retry_delay); current_retry_delay = min(current_retry_delay*2, 60); continue
        except APIResponseError as e:
            logger.error(f"Erreur API Notion pour Recettes: {e.code} - {e.message}.")
            if e.code in ["validation_error", "invalid_json", "unauthorized", "restricted_resource"]: logger.error("Erreur API non r√©cup√©rable pour Recettes. Abandon."); break
            retries += 1; logger.warning(f"Erreur API Recettes (tentative {retries}/{MAX_RETRIES}). Attente {current_retry_delay}s...")
            if retries >= MAX_RETRIES: logger.error(f"Max erreurs API atteintes pour Recettes. Abandon."); break
            time.sleep(current_retry_delay); current_retry_delay = min(current_retry_delay*2, 60); continue
        except Exception as e:
            logger.error(f"Erreur inattendue pour Recettes: {e}", exc_info=True); break

        if not pages_batch:
            if total_extracted_from_api == 0:
                 logger.critical("!!! AUCUNE PAGE RECETTE RETOURN√âE PAR L'API AVEC LE FILTRE ACTUEL !!!")
                 logger.critical("Cause probable : Noms de propri√©t√©s incorrects dans le filtre OU conditions du filtre trop restrictives OU permissions de l'int√©gration.")
                 logger.critical(f"Filtre utilis√© : {filter_recettes}")
            else:
                 logger.info("Plus de pages Recettes √† r√©cup√©rer de l'API.")
            break

        for page in pages_batch:
            page_props_raw = page.get("properties", {})
            row_data = {}
            for csv_col_name, (notion_prop_name_key, expected_format_key) in csv_to_notion_mapping.items():
                if csv_col_name == "Page_ID":
                    row_data[csv_col_name] = page.get("id", "")
                else:
                    raw_prop_data = page_props_raw.get(notion_prop_name_key)
                    if raw_prop_data is None and notion_prop_name_key is not None:
                         logger.warning(f"Propri√©t√© Notion '{notion_prop_name_key}' (pour CSV '{csv_col_name}') non trouv√©e dans la page ID {page.get('id')}. Cl√©s dispo: {list(page_props_raw.keys())}")
                    row_data[csv_col_name] = extract_recette_property_value(raw_prop_data, notion_prop_name_key, expected_format_key)
            all_recettes_rows.append(row_data)

        if not next_cursor or total_extracted_from_api >= NUM_ROWS_TO_EXTRACT:
            logger.info("Fin de l'extraction des recettes (plus de pages ou limite atteinte).")
            break
        time.sleep(0.35)

    if all_recettes_rows:
        df = pd.DataFrame(all_recettes_rows)
        logger.info(f"Extraction des recettes r√©ussie : {len(df)} recettes charg√©es.")
        return df
    else:
        logger.info(f"Aucune recette extraite de {DATABASE_ID_RECETTES}.")
        return pd.DataFrame()

# --- Fonctions de traitement des donn√©es existantes ---
def process_data(df_planning, df_recettes, df_ingredients, df_ingredients_recettes):
    st.info("Traitement des donn√©es en cours...")
    logger.info("D√©but du traitement des donn√©es.")

    # Nettoyage des noms de colonnes : suppression des espaces superflus et caract√®res sp√©ciaux
    df_planning.columns = [col.strip().replace(" ", "_").replace("(", "").replace(")", "").replace("√©", "e").replace("√†", "a").replace("√ß", "c").lower() for col in df_planning.columns]
    df_recettes.columns = [col.strip().replace(" ", "_").replace("(", "").replace(")", "").replace("√©", "e").replace("√†", "a").replace("√ß", "c").lower() for col in df_recettes.columns]
    df_ingredients.columns = [col.strip().replace(" ", "_").replace("(", "").replace(")", "").replace("√©", "e").replace("√†", "a").replace("√ß", "c").lower() for col in df_ingredients.columns]
    df_ingredients_recettes.columns = [col.strip().replace(" ", "_").replace("(", "").replace(")", "").replace("√©", "e").replace("√†", "a").replace("√ß", "c").lower() for col in df_ingredients_recettes.columns]

    df_planning['date'] = pd.to_datetime(df_planning['date'], format='%d/%m/%Y')
    df_planning.set_index('date', inplace=True)

    df_recettes['nom'] = df_recettes['nom'].str.strip()

    df_ingredients_recettes['recette'] = df_ingredients_recettes['recette'].str.strip()
    df_ingredients_recettes['ingredient'] = df_ingredients_recettes['ingredient'].str.strip()

    df_ingredients['nom'] = df_ingredients['nom'].str.strip()

    # Fusion des dataframes
    df_menus = df_planning.stack().reset_index()
    df_menus.columns = ['date', 'repas_type', 'recette_nom']
    df_menus['date'] = df_menus['date'].dt.strftime('%d/%m/%Y')

    # Remplacer les valeurs vides ou "None" par une cha√Æne vide
    df_menus['recette_nom'] = df_menus['recette_nom'].fillna('').astype(str).str.strip()

    # Nettoyer les noms des colonnes 'repas_type' pour correspondre aux propri√©t√©s Notion
    df_menus['repas_type'] = df_menus['repas_type'].str.replace('_', ' ').str.title()
    df_menus['repas_type'] = df_menus['repas_type'].replace({
        'Dejeuner': 'D√©jeuner',
        'Diner': 'D√Æner'
    })

    df_menus_complet = pd.merge(df_menus, df_recettes, left_on='recette_nom', right_on='nom', how='left')
    df_menus_complet.rename(columns={'nom': 'Nom Recette', 'participants': 'Participant(s)'}, inplace=True)

    # Utilisation de DATABASE_ID_RECETTES pour chercher l'ID de la recette
    df_menus_complet['Recette ID'] = df_menus_complet['recette_nom'].apply(lambda x: get_page_id_by_name(DATABASE_ID_RECETTES, "Nom", x) if x else None) # Assurez-vous que "Nom" est la propri√©t√© de titre de votre base de recettes

    st.success("Traitement des donn√©es termin√©.")
    logger.info("Fin du traitement des donn√©es.")

    return df_menus_complet, df_ingredients, df_ingredients_recettes

def generate_output_files(df_menus_complet, df_ingredients, df_ingredients_recettes):
    st.info("G√©n√©ration des fichiers de sortie en cours...")
    logger.info("D√©but de la g√©n√©ration des fichiers de sortie.")

    # Pr√©paration du DataFrame pour l'export CSV
    df_menu_genere = df_menus_complet[['date', 'Participant(s)', 'recette_nom']].copy()
    df_menu_genere.rename(columns={'date': 'Date', 'recette_nom': 'Nom'}, inplace=True)

    # Formater les dates pour Notion au format YYYY-MM-DD HH:MM
    # La date dans df_menu_genere est d√©j√† au format DD/MM/YYYY
    # Pour l'export Notion, on peut ajouter une heure par d√©faut si n√©cessaire
    df_menu_genere['Date'] = pd.to_datetime(df_menu_genere['Date'], format="%d/%m/%Y", errors='coerce').dt.strftime('%Y-%m-%d %H:%M')

    # Exporter en CSV pour t√©l√©chargement
    csv_buffer = io.StringIO()
    df_menu_genere.to_csv(csv_buffer, index=False, encoding="utf-8-sig")
    csv_data = csv_buffer.getvalue().encode("utf-8-sig")
    st.download_button(
        label="T√©l√©charger Menus_generes.csv",
        data=csv_data,
        file_name=FICHIER_SORTIE_MENU_CSV,
        mime="text/csv",
    )
    logger.info(f"Fichier CSV '{FICHIER_SORTIE_MENU_CSV}' pr√™t pour t√©l√©chargement.")

    # G√©n√©ration du r√©capitulatif des ingr√©dients
    df_details_ingredients = pd.merge(df_menus_complet, df_ingredients_recettes, left_on='recette_nom', right_on='recette', how='inner')
    df_details_ingredients = pd.merge(df_details_ingredients, df_ingredients, left_on='ingredient', right_on='nom', how='inner', suffixes=('_recette', '_stock'))

    df_details_ingredients['quantite'] = pd.to_numeric(df_details_ingredients['quantite'], errors='coerce').fillna(0)

    # Calcul des quantit√©s totales par ingr√©dient et unit√©
    liste_courses = df_details_ingredients.groupby(['ingredient', 'unite'])['quantite'].sum().reset_index()

    # Comparaison avec le stock (si la colonne 'quantite_stock' existe et est num√©rique)
    if 'quantite_stock' in df_ingredients.columns:
        df_ingredients['quantite_stock'] = pd.to_numeric(df_ingredients['quantite_stock'], errors='coerce').fillna(0)
        liste_courses = pd.merge(liste_courses, df_ingredients[['nom', 'quantite_stock']], left_on='ingredient', right_on='nom', how='left').drop(columns='nom')
        liste_courses['A acheter'] = liste_courses['quantite'] - liste_courses['quantite_stock']
        liste_courses['A acheter'] = liste_courses['A acheter'].apply(lambda x: max(0, x)) # Ne pas afficher de quantit√©s n√©gatives

        # Filtre pour n'afficher que ce qui est √† acheter
        liste_courses = liste_courses[liste_courses['A acheter'] > 0]
        st.subheader("Liste de courses (√©l√©ments √† acheter) :")
        contenu_fichier_recap_txt = ["Liste de courses (√©l√©ments √† acheter) :\n"]
        for _, row in liste_courses.iterrows():
            line = f"- {row['A acheter']:.2f} {row['unite']} de {row['ingredient']}\n"
            contenu_fichier_recap_txt.append(line)
            st.write(line.strip()) # Afficher aussi dans l'app
    else:
        st.subheader("R√©capitulatif des ingr√©dients requis (sans comparaison de stock) :")
        contenu_fichier_recap_txt = ["R√©capitulatif des ingr√©dients requis :\n"]
        for _, row in liste_courses.iterrows():
            line = f"- {row['quantite']:.2f} {row['unite']} de {row['ingredient']}\n"
            contenu_fichier_recap_txt.append(line)
            st.write(line.strip()) # Afficher aussi dans l'app

    txt_buffer = io.StringIO()
    txt_buffer.writelines(contenu_fichier_recap_txt)
    txt_data = txt_buffer.getvalue().encode("utf-8")
    st.download_button(
        label="T√©l√©charger Liste_ingredients.txt",
        data=txt_data,
        file_name=FICHIER_SORTIE_LISTES_TXT,
        mime="text/plain",
    )
    logger.info(f"Fichier TXT '{FICHIER_SORTIE_LISTES_TXT}' pr√™t pour t√©l√©chargement.")
    st.success("G√©n√©ration des fichiers de sortie termin√©e.")

# --- Fonction d'int√©gration Notion (√† adapter si n√©cessaire) ---
def integrate_with_notion(df_menus_complet):
    st.info("Int√©gration avec Notion en cours...")
    logger.info("D√©but de l'int√©gration avec Notion.")

    # Filtrer les lignes qui n'ont pas de recette_nom vide
    df_to_integrate = df_menus_complet[df_menus_complet['recette_nom'] != ''].copy()

    if df_to_integrate.empty:
        st.warning("Aucun menu valide √† int√©grer dans Notion.")
        logger.warning("Aucun menu valide √† int√©grer dans Notion.")
        return

    # V√©rifier l'existence des pages de recettes dans Notion pour r√©cup√©rer les IDs de relation
    recette_ids = {}
    st.info("V√©rification des recettes existantes dans Notion...")
    for recette_nom in df_to_integrate['recette_nom'].unique():
        # Utilisation de DATABASE_ID_RECETTES pour chercher la recette
        page_id = get_page_id_by_name(DATABASE_ID_RECETTES, "Nom", recette_nom)
        if page_id:
            recette_ids[recette_nom] = page_id
        else:
            st.warning(f"La recette '{recette_nom}' n'a pas √©t√© trouv√©e dans Notion. Elle ne sera pas li√©e.")

    for index, row in df_to_integrate.iterrows():
        date_str = row['date']
        repas_type = row['repas_type']
        recette_nom = row['recette_nom']
        participants = row['Participant(s)']

        properties = {
            "Date": {
                "date": {
                    "start": datetime.strptime(date_str, '%d/%m/%Y').isoformat()
                }
            },
            "Repas": {
                "select": {
                    "name": repas_type
                }
            },
            "Nom": {
                "title": [
                    {
                        "text": {
                            "content": f"{repas_type} - {recette_nom} ({date_str})"
                        }
                    }
                ]
            },
            "Participant(s)": {
                "rich_text": [
                    {
                        "text": {
                            "content": str(participants)
                        }
                    }
                ]
            }
        }

        if recette_nom in recette_ids:
            properties["Recette"] = {
                "relation": [{"id": recette_ids[recette_nom]}]
            }
        else:
            st.warning(f"Impossible de lier la recette '{recette_nom}' pour le {repas_type} du {date_str} car elle n'a pas √©t√© trouv√©e dans Notion.")

        existing_page_id = get_page_id_by_name(DATABASE_ID_MENUS, "Nom", properties["Nom"]["title"][0]["text"]["content"])

        if existing_page_id:
            st.info(f"La page pour '{repas_type} - {recette_nom} ({date_str})' existe d√©j√†. Mise √† jour en cours...")
            pass
        else:
            st.info(f"Cr√©ation de la page pour '{repas_type} - {recette_nom} ({date_str})'...")
            create_page(DATABASE_ID_MENUS, properties)
    st.success("Int√©gration avec Notion termin√©e.")
    logger.info("Fin de l'int√©gration avec Notion.")

# --- Nouvelle Fonction d'extraction des menus existants depuis Notion ---
@st.cache_data(show_spinner="Extraction des menus existants depuis Notion...", ttl=3600)
def get_existing_menus_data():
    all_menus_rows = []
    next_cursor = None
    total_extracted_from_api = 0

    # Noms de propri√©t√©s Notion pour la base de donn√©es des Menus
    nom_menu_property_name = "Nom Menu"
    recette_property_name = "Recette"
    date_property_name = "Date"

    filter_menus = {"property": recette_property_name, "relation": {"is_not_empty": True}}
    logger.info(f"Filtre API Notion pour Menus existants : {filter_menus}")

    while total_extracted_from_api < NUM_ROWS_TO_EXTRACT:
        retries = 0
        current_retry_delay = RETRY_DELAY_INITIAL

        try:
            query_params = {
                "database_id": DATABASE_ID_MENUS,
                "filter": filter_menus,
                "page_size": BATCH_SIZE,
                "timeout": API_TIMEOUT_SECONDS
            }
            if next_cursor: query_params["start_cursor"] = next_cursor

            logger.info(f"Appel API Notion pour Menus (Curseur: {next_cursor or 'aucun'}).")
            response = notion.databases.query(**query_params)

            pages_batch = response.get("results", [])
            total_extracted_from_api += len(pages_batch)
            logger.info(f"API Menus a retourn√© {len(pages_batch)} pages pour ce lot. (Total API: {total_extracted_from_api})")

            next_cursor = response.get("next_cursor")

        except (RequestTimeoutError, httpx.TimeoutException, httpx.ReadTimeout) as e:
            retries += 1; logger.warning(f"Timeout API Menus (tentative {retries}/{MAX_RETRIES}). Attente {current_retry_delay}s...")
            if retries >= MAX_RETRIES: logger.error(f"Max timeouts atteints pour Menus. Abandon."); break
            time.sleep(current_retry_delay); current_retry_delay = min(current_retry_delay*2, 60); continue
        except APIResponseError as e:
            logger.error(f"Erreur API Notion pour Menus: {e.code} - {e.message}.")
            if e.code in ["validation_error", "invalid_json", "unauthorized", "restricted_resource"]: logger.error("Erreur API non r√©cup√©rable pour Menus. Abandon."); break
            retries += 1; logger.warning(f"Erreur API Menus (tentative {retries}/{MAX_RETRIES}). Attente {current_retry_delay}s...")
            if retries >= MAX_RETRIES: logger.error(f"Max erreurs API atteintes pour Menus. Abandon."); break
            time.sleep(current_retry_delay); current_retry_delay = min(current_retry_delay*2, 60); continue
        except Exception as e:
            logger.error(f"Erreur inattendue pour Menus: {e}", exc_info=True); break

        if not pages_batch:
            if total_extracted_from_api == 0:
                 logger.critical("!!! AUCUNE PAGE MENU RETOURN√âE PAR L'API AVEC LE FILTRE ACTUEL !!!")
                 logger.critical("Cause probable : Noms de propri√©t√©s incorrects dans le filtre OU conditions du filtre trop restrictives OU permissions de l'int√©gration.")
                 logger.critical(f"Filtre utilis√© : {filter_menus}")
            else:
                 logger.info("Plus de pages Menus √† r√©cup√©rer de l'API.")
            break

        for page in pages_batch:
            properties = page.get("properties", {})
            nom_menu_value = ""
            if nom_menu_property_name in properties:
                name_property = properties[nom_menu_property_name]
                nom_menu_value = "".join([text.get("plain_text", "") for text in name_property.get("title", []) or name_property.get("rich_text", [])])

            recette_value = ""
            if recette_property_name in properties:
                prop = properties[recette_property_name]
                if prop["type"] == "relation" and prop["relation"]:
                    recette_value = ", ".join([relation["id"] for relation in prop["relation"]])
                elif prop["type"] == "rollup" and prop["rollup"]:
                    rollup_data = prop["rollup"]
                    if rollup_data.get("type") == "array" and rollup_data.get("array"):
                        recette_ids = []
                        for item in rollup_data["array"]:
                            if item.get("id"):
                                recette_ids.append(item["id"])
                            elif item.get("relation"):
                                recette_ids.extend([rel.get("id") for rel in item["relation"] if rel.get("id")])
                        recette_value = ", ".join(recette_ids)

            date_value = ""
            if date_property_name in properties:
                date_property = properties[date_property_name]
                if date_property["type"] == "date" and date_property.get("date") and date_property["date"].get("start"):
                    date_str = date_property["date"]["start"]
                    date_object = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                    date_value = date_object.strftime('%Y-%m-%d')

            all_menus_rows.append({
                "Nom Menu": nom_menu_value.strip(),
                "Recette": recette_value,
                "Date": date_value
            })

        if not next_cursor or total_extracted_from_api >= NUM_ROWS_TO_EXTRACT:
            logger.info("Fin de l'extraction des menus existants (plus de pages ou limite atteinte).")
            break
        time.sleep(0.35)

    if all_menus_rows:
        df = pd.DataFrame(all_menus_rows)
        logger.info(f"Extraction des menus existants r√©ussie : {len(df)} menus charg√©s.")
        return df
    else:
        logger.info(f"Aucun menu extrait de {DATABASE_ID_MENUS}.")
        return pd.DataFrame()


# --- Application Streamlit principale ---
def main():
    st.set_page_config(layout="wide", page_title="G√©n√©rateur de Menus Notion")
    st.title("üçΩÔ∏è G√©n√©rateur de Menus pour Notion")

    st.markdown("""
    Cette application vous permet de g√©n√©rer des menus, des listes d'ingr√©dients,
    et de les synchroniser avec votre base de donn√©es Notion "Planning Menus".
    """)

    st.sidebar.header("Chargement des Donn√©es")

    # Bouton de r√©initialisation/rechargement global pour Notion
    st.sidebar.markdown("---")
    st.sidebar.subheader("Actions de Rechargement")
    st.sidebar.info("Note : Le fichier 'Planning.csv' doit √™tre recharg√© manuellement via le bouton ci-dessous apr√®s une r√©initialisation.")

    if st.sidebar.button("‚ú® Recharger toutes les donn√©es Notion", help="Vide le cache Streamlit et recharge toutes les donn√©es depuis Notion."):
        st.cache_data.clear() # Vide le cache des fonctions d√©cor√©es
        # Ces DataFrames seront recharg√©s par les appels suivants √† get_..._data()
        st.session_state['df_ingredients'] = pd.DataFrame()
        st.session_state['df_ingredients_recettes'] = pd.DataFrame()
        st.session_state['df_recettes'] = pd.DataFrame()
        st.session_state['df_menus_notion'] = pd.DataFrame() # Nouvelle ligne pour les menus existants

        st.success("Cache et DataFrames Notion r√©initialis√©s. Rechargement des donn√©es...")
        # Forcer le rechargement via les fonctions d'obtention de donn√©es
        with st.spinner("Rechargement des ingr√©dients..."):
            st.session_state['df_ingredients'] = get_ingredients_data()
        with st.spinner("Rechargement des ingr√©dients par recette..."):
            st.session_state['df_ingredients_recettes'] = get_ingredients_recettes_data()
        with st.spinner("Rechargement des recettes..."):
            st.session_state['df_recettes'] = get_recettes_data()
        with st.spinner("Rechargement des menus existants..."):
            st.session_state['df_menus_notion'] = get_existing_menus_data() # Nouvelle ligne

        st.success("Toutes les donn√©es Notion ont √©t√© recharg√©es.")
        st.rerun() # Recharge l'application pour afficher les nouvelles donn√©es

    st.sidebar.markdown("---") # S√©parateur visuel

    # 1. Chargement du fichier Planning.csv
    st.sidebar.subheader("1. Fichier Planning des Repas (.csv)")
    uploaded_planning_file = st.sidebar.file_uploader(
        "Choisissez votre fichier Planning.csv", type=["csv"], key="planning_uploader"
    )

    # Initialisation des DataFrames dans session_state si non pr√©sents
    if 'df_planning' not in st.session_state:
        st.session_state['df_planning'] = pd.DataFrame()
    if 'df_ingredients' not in st.session_state:
        st.session_state['df_ingredients'] = pd.DataFrame()
    if 'df_ingredients_recettes' not in st.session_state:
        st.session_state['df_ingredients_recettes'] = pd.DataFrame()
    if 'df_recettes' not in st.session_state:
        st.session_state['df_recettes'] = pd.DataFrame()
    if 'df_menus_notion' not in st.session_state: # Initialisation pour les menus existants
        st.session_state['df_menus_notion'] = pd.DataFrame()

    if uploaded_planning_file is not None:
        try:
            df_planning_loaded = pd.read_csv(uploaded_planning_file, sep=None, engine='python')
            st.session_state['df_planning'] = df_planning_loaded
            st.sidebar.success("Fichier Planning.csv charg√© avec succ√®s.")
        except Exception as e:
            st.sidebar.error(f"Erreur lors du chargement de Planning.csv: {e}")
            st.session_state['df_planning'] = pd.DataFrame()
    else:
        st.sidebar.info("Veuillez charger votre fichier Planning.csv.")

    # Chargement automatique des donn√©es Notion au d√©marrage ou si elles sont vides
    # Ces appels utiliseront le cache si les donn√©es sont d√©j√† l√†, ou referont la requ√™te sinon.
    if st.session_state['df_ingredients'].empty:
        st.session_state['df_ingredients'] = get_ingredients_data()
    if st.session_state['df_ingredients_recettes'].empty:
        st.session_state['df_ingredients_recettes'] = get_ingredients_recettes_data()
    if st.session_state['df_recettes'].empty:
        st.session_state['df_recettes'] = get_recettes_data()
    if st.session_state['df_menus_notion'].empty: # Chargement auto pour les menus existants
        st.session_state['df_menus_notion'] = get_existing_menus_data()


    # Affichage des statuts de chargement des donn√©es Notion
    st.sidebar.subheader("2. Statut des Donn√©es Notion")
    if not st.session_state['df_ingredients'].empty:
        st.sidebar.write(f"‚úÖ Ingr√©dients : {len(st.session_state['df_ingredients'])} lignes.")
    else:
        st.sidebar.write("‚ùå Ingr√©dients : non charg√©.")
    if not st.session_state['df_ingredients_recettes'].empty:
        st.sidebar.write(f"‚úÖ Ingr√©dients/Recette : {len(st.session_state['df_ingredients_recettes'])} lignes.")
    else:
        st.sidebar.write("‚ùå Ingr√©dients/Recette : non charg√©.")
    if not st.session_state['df_recettes'].empty:
        st.sidebar.write(f"‚úÖ Recettes : {len(st.session_state['df_recettes'])} lignes.")
    else:
        st.sidebar.write("‚ùå Recettes : non charg√©.")
    if not st.session_state['df_menus_notion'].empty: # Statut pour les menus existants
        st.sidebar.write(f"‚úÖ Menus existants : {len(st.session_state['df_menus_notion'])} lignes.")
    else:
        st.sidebar.write("‚ùå Menus existants : non charg√©.")


    st.header("1. V√©rification des Donn√©es Charg√©es")
    if not st.session_state['df_planning'].empty:
        st.write("‚úÖ Planning.csv est charg√©.")
        st.subheader("Aper√ßu de Planning.csv :")
        st.dataframe(st.session_state['df_planning'].head())
    else:
        st.write("‚ùå Planning.csv n'est pas encore charg√©. Veuillez le charger dans la barre lat√©rale.")

    if not st.session_state['df_ingredients'].empty:
        st.write("‚úÖ Donn√©es Ingr√©dients (Notion) charg√©es.")
        st.subheader("Aper√ßu de la table Ingr√©dients (Notion) :")
        st.dataframe(st.session_state['df_ingredients'].head())
    else:
        st.write("‚ùå Donn√©es Ingr√©dients (Notion) manquantes ou non charg√©es.")

    if not st.session_state['df_ingredients_recettes'].empty:
        st.write("‚úÖ Donn√©es Ingr√©dients par Recette (Notion) charg√©es.")
        st.subheader("Aper√ßu de la table Ingr√©dients par Recette (Notion) :")
        st.dataframe(st.session_state['df_ingredients_recettes'].head())
    else:
        st.write("‚ùå Donn√©es Ingr√©dients par Recette (Notion) manquantes ou non charg√©es.")

    if not st.session_state['df_recettes'].empty:
        st.write("‚úÖ Donn√©es Recettes (Notion) charg√©es.")
        st.subheader("Aper√ßu de la table Recettes (Notion) :")
        st.dataframe(st.session_state['df_recettes'].head())
    else:
        st.write("‚ùå Donn√©es Recettes (Notion) manquantes ou non charg√©es.")

    if not st.session_state['df_menus_notion'].empty: # Affichage des menus existants
        st.write("‚úÖ Donn√©es Menus existants (Notion) charg√©es.")
        st.subheader("Aper√ßu de la table Menus existants (Notion) :")
        st.dataframe(st.session_state['df_menus_notion'].head())
    else:
        st.write("‚ùå Donn√©es Menus existants (Notion) manquantes ou non charg√©es.")


    st.header("2. G√©n√©rer les menus et listes")
    # Condition pour activer le bouton de g√©n√©ration
    if all(df is not None and not df.empty for df in [st.session_state['df_planning'], st.session_state['df_recettes'], st.session_state['df_ingredients'], st.session_state['df_ingredients_recettes']]):
        if st.button("G√©n√©rer les Menus et Listes"):
            with st.spinner("G√©n√©ration en cours..."):
                df_menus_complet, df_ingredients_processed, df_ingredients_recettes_processed = process_data(
                    st.session_state['df_planning'], st.session_state['df_recettes'],
                    st.session_state['df_ingredients'], st.session_state['df_ingredients_recettes']
                )

                if not df_menus_complet.empty:
                    st.subheader("Aper√ßu des Menus G√©n√©r√©s :")
                    st.dataframe(df_menus_complet[['date', 'repas_type', 'recette_nom', 'Participant(s)']])

                    generate_output_files(df_menus_complet, df_ingredients_processed, df_ingredients_recettes_processed)

                    st.header("3. Int√©grer avec Notion")
                    notion_integrate = st.checkbox("Envoyer les menus g√©n√©r√©s √† Notion?")
                    if notion_integrate:
                        if st.button("Lancer l'int√©gration Notion"):
                            with st.spinner("Int√©gration Notion en cours..."):
                                integrate_with_notion(df_menus_complet)
                                st.success("Processus d'int√©gration Notion termin√©.")
                else:
                    st.warning("Aucun menu n'a pu √™tre g√©n√©r√©. Veuillez v√©rifier vos fichiers.")
    else:
        st.warning("Veuillez charger tous les fichiers CSV n√©cessaires et les donn√©es Notion pour activer la g√©n√©ration.")


    st.header("4. Extraire les Menus existants depuis Notion")
    st.markdown("Cette section vous permet de t√©l√©charger un fichier CSV contenant les menus actuellement enregistr√©s dans votre base de donn√©es Notion.")

    if st.button("Extraire et T√©l√©charger les Menus de Notion"):
        with st.spinner("Extraction en cours depuis Notion..."):
            csv_data_extracted = get_existing_menus_data() # Appelle la fonction qui retourne d√©j√† les donn√©es
            if csv_data_extracted is not None and not csv_data_extracted.empty:
                # Convertir le DataFrame en CSV pour le t√©l√©chargement
                csv_buffer = io.StringIO()
                csv_data_extracted.to_csv(csv_buffer, index=False, encoding="utf-8-sig")
                csv_bytes = csv_buffer.getvalue().encode("utf-8-sig")

                st.download_button(
                    label="T√©l√©charger Menus_extraits_Notion.csv",
                    data=csv_bytes,
                    file_name=FICHIER_EXPORT_NOTION_CSV,
                    mime="text/csv",
                )
                st.success("Fichier d'extraction Notion pr√™t au t√©l√©chargement.")
            else:
                st.error("L'extraction des menus existants depuis Notion a √©chou√© ou n'a retourn√© aucune donn√©e.")


    st.info("N'oubliez pas de configurer vos secrets Notion dans Streamlit Cloud.")


if __name__ == "__main__":
    main()
